\BOOKMARK [0][-]{chapter.1}{Mathematical Foundation}{}% 1
\BOOKMARK [1][-]{section.1.1}{Probability theory and mathematical statistics}{chapter.1}% 2
\BOOKMARK [2][-]{subsection.1.1.1}{How to get expected value and variance?}{section.1.1}% 3
\BOOKMARK [2][-]{subsection.1.1.2}{Discrete probability distribution}{section.1.1}% 4
\BOOKMARK [2][-]{subsection.1.1.3}{Continuous probability distribution}{section.1.1}% 5
\BOOKMARK [2][-]{subsection.1.1.4}{Sample mean and sample variance}{section.1.1}% 6
\BOOKMARK [1][-]{section.1.2}{Prior and posterior}{chapter.1}% 7
\BOOKMARK [0][-]{chapter.2}{Machine Learning}{}% 8
\BOOKMARK [1][-]{section.2.1}{Why can't perceptron solve XOR problem?}{chapter.2}% 9
\BOOKMARK [2][-]{subsection.2.1.1}{Definition of perceptron}{section.2.1}% 10
\BOOKMARK [2][-]{subsection.2.1.2}{Learning Algorithm}{section.2.1}% 11
\BOOKMARK [2][-]{subsection.2.1.3}{Dual form of perceptron learning algorithm}{section.2.1}% 12
\BOOKMARK [1][-]{section.2.2}{How to get the update rule of parameters of backpropagation in gradient descent algorithm?}{chapter.2}% 13
\BOOKMARK [1][-]{section.2.3}{Generative model and discriminative model}{chapter.2}% 14
\BOOKMARK [1][-]{section.2.4}{Support vector machine}{chapter.2}% 15
\BOOKMARK [0][-]{chapter.3}{Deep Network}{}% 16
\BOOKMARK [1][-]{section.3.1}{How does backpropagation work?}{chapter.3}% 17
\BOOKMARK [1][-]{section.3.2}{How does batch normalization work?}{chapter.3}% 18
\BOOKMARK [2][-]{subsection.3.2.1}{Dataset shift and covariate shift}{section.3.2}% 19
\BOOKMARK [2][-]{subsection.3.2.2}{Internal covariate shift}{section.3.2}% 20
\BOOKMARK [2][-]{subsection.3.2.3}{Batch normalization}{section.3.2}% 21
\BOOKMARK [1][-]{section.3.3}{Why does residual learning work?}{chapter.3}% 22
\BOOKMARK [0][-]{chapter.4}{Contents specifically referenced}{}% 23
